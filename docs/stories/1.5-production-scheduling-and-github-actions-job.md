# Story 1.5: Production Scheduling & GitHub Actions Job

## Status

Ready for Review

## Story

**As** the creator and operator of Timing Terminal  
**I want** a production-grade daily scheduling setup using GitHub Actions to run the Bitcoin phase-scoring pipeline  
**so that** `chart-data.json` and the static chart are reliably updated every day with clear, observable failure modes.

## Acceptance Criteria

1. A GitHub Actions workflow file exists (e.g., `.github/workflows/pipeline-daily.yml`) that:
   - Runs on a schedule (cron) at least once per day in UTC.
   - Can also be triggered manually (workflow_dispatch) for ad-hoc runs.
   - Uses the project’s `uv`-based setup to install dependencies and run the pipeline CLI.
2. The workflow runs the existing pipeline CLI end-to-end and:
   - Produces an updated `chart-data.json` artifact.
   - Fails fast (non-zero exit) on schema, scoring, or data-quality regressions as enforced by tests.
   - Surfaces logs sufficient to debug pipeline failures (including `dataQuality` and summary output).
3. Secrets and configuration required for provider mode (if enabled) are injected via GitHub Actions secrets, not committed to the repo.
4. The workflow integrates with the existing testing strategy:
   - Runs unit + integration tests for the pipeline as part of the scheduled job (or in a preceding job).
   - Marks the build red if tests or the pipeline CLI fail.
5. Basic observability is in place for scheduled runs:
   - On success, a concise summary (including phase score range and `dataQuality`) is available via logs or a simple notification hook.
   - On failure, the workflow clearly indicates the failing step and surfaces enough context for manual investigation.
6. Documentation exists explaining how to:
   - Configure and enable the scheduled workflow.
   - Run the pipeline via the workflow manually for debugging.
   - Rotate or update secrets safely.

## Tasks / Subtasks

- [x] **Task 1 – Define GitHub Actions workflow for daily pipeline runs** (AC: 1, 2)
  - [x] Create `.github/workflows/pipeline-daily.yml` with:
    - `on.schedule` cron expression for a daily UTC run.  
    - `on.workflow_dispatch` for manual triggers.  
    - Jobs to check out the repo, set up Python 3.11, and install dependencies via `uv`.
  - [x] Ensure the workflow runs on an appropriate GitHub-hosted runner (e.g., `ubuntu-latest`).

- [x] **Task 2 – Wire pipeline CLI into workflow** (AC: 2, 4)
  - [x] Add a job step to run the pipeline CLI (e.g., `uv run timing-terminal-pipeline` in the `pipeline` directory) in fixture mode by default.
  - [x] Ensure the step fails the job on non-zero exit codes from the pipeline.
  - [x] Add steps to run pipeline unit + integration tests before or as part of the scheduled job; fail the workflow if tests fail.

- [x] **Task 3 – Provider mode configuration & secrets handling** (AC: 3)
  - [x] Identify environment variables required for provider mode based on `config.py`.
    - Currently, only `TT_PIPELINE_MODE` is used to toggle between `fixture` and `provider` modes; the provider still uses the in-memory abstraction and does not require external API keys yet.
  - [x] Document how GitHub Actions injects this configuration:
    - Repository/organization variable `TT_PIPELINE_MODE` (e.g., `provider`) is read by the workflow; it defaults to `fixture` when unset.
  - [x] Update the workflow to conditionally run in provider mode when the variable is set, keeping fixture mode as the safe default.

- [x] **Task 4 – Logging and observability** (AC: 2, 5)
  - [x] Ensure the pipeline CLI prints a concise summary line including point count, current phase score range, and `dataQuality`.
  - [x] Confirm that GitHub Actions logs preserve this summary and are easy to locate.
  - [x] (Optional, if in scope) Add a minimal notification hook (e.g., Discord webhook step) that posts success/failure based on workflow status, with `dataQuality` available in logs/JSON.

- [x] **Task 5 – Documentation and runbook** (AC: 6)
  - [x] Add/update a `docs/` or `README` section describing:
    - The purpose and schedule of the `pipeline-daily` workflow.
    - How to trigger runs manually from the GitHub UI.
    - How to configure and rotate GitHub Actions secrets used by the pipeline.
    - Where to look in logs for pipeline summary output and common failure patterns.

## Dev Notes

> All technical guidance here is derived from the PRD and Architecture; no new libraries or patterns are invented.

### Context from Epic 1 & Previous Stories

- **Epic 1 Goal:** Establish a reliable, testable data pipeline that computes the Bitcoin phase score and produces `chart-data.json` for the Timing Terminal chart. Story 1.5 is explicitly defined as **“Production Scheduling & GitHub Actions Job”**, responsible for daily automation.  
  _[Source: `docs/stories/epic-1.data-pipeline.md#Story 1.5 – Production Scheduling & GitHub Actions Job`]_
- **Stories 1.1–1.4** have already:
  - Bootstrapped the pipeline, models, and CLI, generating `chart-data.json` (Story 1.1).  
  - Implemented `dataQuality` semantics and tests (Story 1.2).  
  - Implemented the phase scoring engine and zone classification (Story 1.3).  
  - Added a provider abstraction, `TT_PIPELINE_MODE` toggle, and optional LTH inputs (Story 1.4).  
  Story 1.5 builds on this, focusing on **orchestration and reliability in production** rather than new data transforms.

### Architecture & Tech Stack Alignment

- **Scheduling & CI:** Architecture specifies **GitHub Actions scheduled workflow (cron)** as the primary mechanism for daily runs of the pipeline.  
  _[Source: `docs/architecture.md#Tech Stack`, Scheduling row]_  
- **Backend & Packaging:**
  - Python 3.11 is the canonical runtime for the data pipeline.  
  - `uv` is the package manager for installing and running the pipeline in CI.  
  _[Source: `docs/architecture.md#Tech Stack`, Backend / Data Pipeline]_  
- **Data Models & Contract:** The pipeline must continue to produce `chart-data.json` with the documented schema (`btcPrice[]`, `phaseScore[]`, `lastUpdated`, `dataQuality`).  
  _[Source: `docs/architecture.md#Data Models`, `#JSON Schema (chart-data.json)`]_  
- **Data Quality:** `dataQuality` is computed via `evaluate_data_quality` with semantics for `complete`, `partial`, and `stale`. CI should treat regressions in `dataQuality` behavior (e.g., failing tests) as build failures.  
  _[Source: `docs/architecture.md#Data Quality`]_

### Project Structure Expectations

- Existing stories use and reinforce a unified project structure:  
  ```text
  pipeline/
    timing_terminal/
      providers/
      scoring/
      data_providers/
      models.py
      config.py
      cli.py
    tests/
      unit/
      integration/
  ```  
  _[Source: `docs/stories/1.1.data-pipeline-bootstrap.md#Project Structure Alignment`, `docs/stories/1.2-pipeline-partial-data-handling.md`, `docs/stories/1.3-phase-scoring-engine.md`, `docs/stories/1.4-phase-input-provider-integration.md`]_
- Story 1.5 should **not** change this layout; it introduces CI configuration under `.github/workflows/` and, if needed, small documentation updates only.

### Testing Standards (from Architecture)

- **Unit Tests:**
  - Cover pure functions in the pipeline (e.g., scoring, data quality evaluation).  
  - Live under `pipeline/tests/unit/` and run via `pytest`.  
  _[Source: `docs/architecture.md#Testing & Quality`, `#Testing Strategy`]_
- **Integration Tests:**
  - Exercise the CLI end-to-end to validate `chart-data.json` schema, time alignment, and `dataQuality` behavior.  
  - Live under `pipeline/tests/integration/`.  
  _[Source: `docs/architecture.md#Testing Strategy`, `#Pipeline Integration Tests`]_
- **CI Expectations:**
  - CI (including scheduled runs) should treat failing unit/integration tests as **red builds**.  
  - Pipeline regressions in schema or scoring logic must fail the workflow early rather than silently emitting broken `chart-data.json`.  
  _[Source: `docs/architecture.md#Testing & Quality`, `#Monitoring as a Testing Backstop`]_

### Monitoring & Observability Hooks

- Architecture calls for:
  - Discord webhooks for pipeline success/failure and current phase score, especially during decision-critical zones (<20 or >80).  
  - Clear visibility into `dataQuality` to support operational decision-making.  
  _[Source: `docs/architecture.md#Monitoring & Alerts`, `#Data Quality`, `#Phase-Based Architectural Changes`]_
- Story 1.5 should at minimum ensure that:
  - The scheduled job’s logs show the summary line from the CLI (including `dataQuality`).  
  - The workflow structure makes it straightforward to add Discord or other notification steps in a follow-up story, without redesigning the job.

### Technical Constraints & Non-Goals

- **Must:**
  - Use Python 3.11 and `uv` in CI to match local development.  
  - Keep scheduled workflow deterministic and free of live external variability in tests (provider mode must rely on deterministic fixtures).  
- **Must not:**
  - Introduce new third-party CI services or change hosting (Netlify remains hosting platform).  
  - Commit secrets or provider credentials to the repo; they must live in GitHub Actions secrets.

### Open Questions / To Clarify During Implementation

- Exact cron schedule (e.g., `0 6 * * *` vs another hour) should be chosen based on operational preference; this story can set a reasonable default and document how to adjust it.
- Whether Discord or other notifications are wired in this story or left for a subsequent “observability hardening” story; ACs treat it as optional but recommended.

## Testing

- **Unit Tests:**
  - No new pure-Python units are strictly required for this story if the workflow only orchestrates existing code.
  - If helper scripts are added (e.g., a small wrapper around the CLI), they should be covered with unit tests under `pipeline/tests/unit/`.

- **Integration / CI Tests:**
  - Reuse existing integration tests by running `pytest` in the scheduled workflow as a first step.
  - Optionally, add a smoke test job that:
    - Runs the pipeline CLI.
    - Asserts the presence of `chart-data.json` at the expected path.  
    - Verifies that the process exits 0 and logs contain the summary line.

## Change Log

| Date       | Version | Description                                           | Author       |
|------------|---------|-------------------------------------------------------|--------------|
| 2025-12-09 | v0.1    | Initial draft of Story 1.5 created                    | Scrum Master |
