# Brownfield Project Migration Task

**Purpose:** Analyze an existing codebase and onboard it into the BMAD workflow by detecting project structure, tech stack, existing documentation, and creating appropriate BMAD artifacts.

**When to Use:** When dropping the BMAD template into an existing project that was NOT created with BMAD.

**Instructions for Orchestrator:** Execute each phase sequentially. Present findings to user at checkpoints. Do NOT skip phases.

---

## Phase 1: Environment & VCS Analysis

### 1.1 Git Repository Status

```bash
echo "=== GIT ANALYSIS ==="
git rev-parse --is-inside-work-tree 2>/dev/null && echo "âœ“ Git initialized" || echo "âœ— Not a git repo"
git remote -v 2>/dev/null || echo "No remotes configured"
git branch -a 2>/dev/null | head -20
echo -e "\nCurrent branch: $(git branch --show-current 2>/dev/null || echo 'N/A')"
echo -e "\nRecent commits:"
git --no-pager log --oneline -10 2>/dev/null || echo "No commits"
echo -e "\nUncommitted changes:"
git status --porcelain 2>/dev/null | head -20
```

### 1.2 Project Root Structure

```bash
echo "=== PROJECT STRUCTURE ==="
ls -la
echo -e "\n=== DIRECTORY TREE (2 levels) ==="
find . -maxdepth 2 -type d ! -path '*/\.*' ! -path './node_modules/*' ! -path './.git/*' ! -path './venv/*' ! -path './__pycache__/*' 2>/dev/null | head -50
```

**Checkpoint 1:** Present VCS status and root structure to user. Ask:
```
I've analyzed the repository structure. Before continuing:
1. Is this the correct project root?
2. Are there any directories I should ignore during analysis?
3. Continue with tech stack detection
```

---

## Phase 2: Tech Stack Detection

### 2.1 Language & Framework Detection

```bash
echo "=== LANGUAGE/FRAMEWORK DETECTION ==="

# Python
[ -f "requirements.txt" ] && echo "âœ“ Python (requirements.txt)" && head -20 requirements.txt
[ -f "pyproject.toml" ] && echo "âœ“ Python (pyproject.toml)" && head -30 pyproject.toml
[ -f "setup.py" ] && echo "âœ“ Python (setup.py)"
[ -f "Pipfile" ] && echo "âœ“ Python (Pipfile)"
[ -d "venv" ] || [ -d ".venv" ] && echo "âœ“ Python virtualenv detected"

# JavaScript/TypeScript
[ -f "package.json" ] && echo "âœ“ Node.js (package.json)" && cat package.json | head -50
[ -f "tsconfig.json" ] && echo "âœ“ TypeScript"
[ -f "bun.lockb" ] && echo "âœ“ Bun runtime"
[ -d "node_modules" ] && echo "âœ“ node_modules present"

# Go
[ -f "go.mod" ] && echo "âœ“ Go (go.mod)" && cat go.mod
[ -f "go.sum" ] && echo "âœ“ Go dependencies locked"

# Rust
[ -f "Cargo.toml" ] && echo "âœ“ Rust (Cargo.toml)" && head -30 Cargo.toml

# Ruby
[ -f "Gemfile" ] && echo "âœ“ Ruby (Gemfile)" && head -20 Gemfile

# Java/Kotlin
[ -f "pom.xml" ] && echo "âœ“ Java/Maven"
[ -f "build.gradle" ] || [ -f "build.gradle.kts" ] && echo "âœ“ Gradle"

# .NET
[ -f "*.csproj" ] 2>/dev/null && echo "âœ“ .NET"
[ -f "*.sln" ] 2>/dev/null && echo "âœ“ .NET Solution"

# PHP
[ -f "composer.json" ] && echo "âœ“ PHP (Composer)"

echo -e "\n=== CONFIG FILES ==="
ls -la *.json *.yaml *.yml *.toml *.ini .env* 2>/dev/null | head -20
```

### 2.2 Framework-Specific Detection

```bash
echo "=== FRAMEWORK DETECTION ==="

# Web Frameworks
[ -d "src/app" ] || [ -d "app" ] && echo "? Possible Next.js/Rails/Laravel app structure"
[ -f "next.config.js" ] || [ -f "next.config.mjs" ] && echo "âœ“ Next.js"
[ -f "nuxt.config.js" ] || [ -f "nuxt.config.ts" ] && echo "âœ“ Nuxt.js"
[ -f "vite.config.js" ] || [ -f "vite.config.ts" ] && echo "âœ“ Vite"
[ -f "webpack.config.js" ] && echo "âœ“ Webpack"
[ -f "angular.json" ] && echo "âœ“ Angular"
[ -f "svelte.config.js" ] && echo "âœ“ SvelteKit"

# Python Frameworks
grep -l "fastapi\|FastAPI" *.py 2>/dev/null && echo "âœ“ FastAPI"
grep -l "flask\|Flask" *.py 2>/dev/null && echo "âœ“ Flask"
grep -l "django\|Django" *.py 2>/dev/null && echo "âœ“ Django"
[ -f "manage.py" ] && echo "âœ“ Django (manage.py)"

# API/Backend
[ -f "openapi.yaml" ] || [ -f "openapi.json" ] || [ -f "swagger.yaml" ] && echo "âœ“ OpenAPI spec found"
[ -d "prisma" ] && echo "âœ“ Prisma ORM"
[ -f "schema.prisma" ] && echo "âœ“ Prisma schema"

# Infrastructure
[ -f "Dockerfile" ] && echo "âœ“ Docker"
[ -f "docker-compose.yml" ] || [ -f "docker-compose.yaml" ] && echo "âœ“ Docker Compose"
[ -f "Makefile" ] && echo "âœ“ Makefile"
[ -d ".github/workflows" ] && echo "âœ“ GitHub Actions" && ls .github/workflows/
[ -f ".gitlab-ci.yml" ] && echo "âœ“ GitLab CI"
[ -f "Jenkinsfile" ] && echo "âœ“ Jenkins"
[ -d "terraform" ] || [ -f "*.tf" ] 2>/dev/null && echo "âœ“ Terraform"
[ -f "serverless.yml" ] && echo "âœ“ Serverless Framework"
```

### 2.3 Testing Setup

```bash
echo "=== TESTING SETUP ==="
[ -f "jest.config.js" ] || [ -f "jest.config.ts" ] && echo "âœ“ Jest"
[ -f "vitest.config.js" ] || [ -f "vitest.config.ts" ] && echo "âœ“ Vitest"
[ -f "pytest.ini" ] || [ -f "pyproject.toml" ] && grep -q "pytest" pyproject.toml 2>/dev/null && echo "âœ“ Pytest"
[ -d "tests" ] || [ -d "test" ] || [ -d "__tests__" ] && echo "âœ“ Test directory found"
[ -f "cypress.config.js" ] || [ -d "cypress" ] && echo "âœ“ Cypress"
[ -f "playwright.config.ts" ] && echo "âœ“ Playwright"

echo -e "\n=== TEST FILES ==="
find . -name "*test*" -o -name "*spec*" 2>/dev/null | grep -v node_modules | grep -v __pycache__ | head -20
```

**Checkpoint 2:** Present detected tech stack. Ask user to confirm/correct:
```
Based on my analysis, here's the detected tech stack:

Languages: [list]
Frameworks: [list]
Build Tools: [list]
Testing: [list]
Infrastructure: [list]

1. Confirm this is accurate
2. Add missing technologies
3. Correct any misdetections
```

---

## Phase 3: Existing Documentation Analysis

### 3.1 Documentation Discovery

```bash
echo "=== DOCUMENTATION DISCOVERY ==="

# Standard docs
[ -f "README.md" ] && echo "âœ“ README.md" && wc -l README.md
[ -f "CONTRIBUTING.md" ] && echo "âœ“ CONTRIBUTING.md"
[ -f "CHANGELOG.md" ] && echo "âœ“ CHANGELOG.md"
[ -f "LICENSE" ] || [ -f "LICENSE.md" ] && echo "âœ“ LICENSE"
[ -f "ARCHITECTURE.md" ] && echo "âœ“ ARCHITECTURE.md (existing)"
[ -f "DESIGN.md" ] && echo "âœ“ DESIGN.md"
[ -f "API.md" ] && echo "âœ“ API.md"

# Docs directories
[ -d "docs" ] && echo "âœ“ docs/ directory" && ls -la docs/ | head -20
[ -d "documentation" ] && echo "âœ“ documentation/ directory"
[ -d "wiki" ] && echo "âœ“ wiki/ directory"
[ -d ".github" ] && echo "âœ“ .github/ directory" && ls .github/

echo -e "\n=== MARKDOWN FILES ==="
find . -name "*.md" ! -path '*/node_modules/*' ! -path '*/.git/*' 2>/dev/null | head -30
```

### 3.2 README Analysis

```bash
echo "=== README CONTENT ANALYSIS ==="
if [ -f "README.md" ]; then
  echo "--- README.md sections ---"
  grep "^#" README.md | head -20
  echo -e "\n--- README.md full content ---"
  cat README.md
fi
```

### 3.3 Code Comments & Inline Docs

```bash
echo "=== INLINE DOCUMENTATION ==="
# Check for JSDoc, docstrings, etc.
echo "Checking for documentation patterns..."

# Python docstrings
find . -name "*.py" ! -path '*/venv/*' ! -path '*/__pycache__/*' -exec grep -l '"""' {} \; 2>/dev/null | head -10 && echo "âœ“ Python docstrings found"

# JSDoc
find . -name "*.js" -o -name "*.ts" ! -path '*/node_modules/*' -exec grep -l '/\*\*' {} \; 2>/dev/null | head -10 && echo "âœ“ JSDoc comments found"

# Go doc comments
find . -name "*.go" -exec grep -l '^//' {} \; 2>/dev/null | head -10 && echo "âœ“ Go doc comments found"
```

**Checkpoint 3:** Present documentation findings:
```
Existing documentation found:

README: [exists/missing] - [brief summary if exists]
Architecture docs: [exists/missing]
API docs: [exists/missing]
Other docs: [list]

1. Continue to source code analysis
2. Show me the README content
3. Show me other documentation
```

---

## Phase 4: Source Code Structure Analysis

### 4.1 Entry Points & Main Files

```bash
echo "=== ENTRY POINTS ==="
# Common entry points
[ -f "main.py" ] && echo "âœ“ main.py"
[ -f "app.py" ] && echo "âœ“ app.py"
[ -f "index.js" ] || [ -f "index.ts" ] && echo "âœ“ index.js/ts"
[ -f "src/index.js" ] || [ -f "src/index.ts" ] && echo "âœ“ src/index.js/ts"
[ -f "src/main.js" ] || [ -f "src/main.ts" ] && echo "âœ“ src/main.js/ts"
[ -f "cmd/main.go" ] && echo "âœ“ cmd/main.go"
[ -f "main.go" ] && echo "âœ“ main.go"
[ -f "src/main.rs" ] && echo "âœ“ src/main.rs"
[ -f "lib/main.dart" ] && echo "âœ“ lib/main.dart"

# Check package.json scripts
if [ -f "package.json" ]; then
  echo -e "\n=== NPM SCRIPTS ==="
  cat package.json | grep -A 20 '"scripts"' | head -25
fi

# Check Makefile targets
if [ -f "Makefile" ]; then
  echo -e "\n=== MAKEFILE TARGETS ==="
  grep "^[a-zA-Z].*:" Makefile | head -20
fi
```

### 4.2 Directory Purpose Inference

```bash
echo "=== DIRECTORY ANALYSIS ==="
for dir in src lib app api components pages routes models controllers services utils helpers hooks types interfaces schemas migrations seeds fixtures config public static assets; do
  [ -d "$dir" ] && echo "âœ“ $dir/" && ls "$dir" 2>/dev/null | head -10
done
```

### 4.3 Database & Data Layer

```bash
echo "=== DATA LAYER ==="
# Database configs
[ -f "prisma/schema.prisma" ] && echo "âœ“ Prisma schema" && head -50 prisma/schema.prisma
[ -d "migrations" ] && echo "âœ“ migrations/" && ls migrations/ | head -10
[ -f "alembic.ini" ] && echo "âœ“ Alembic (SQLAlchemy migrations)"
[ -d "alembic" ] && echo "âœ“ alembic/" && ls alembic/versions/ 2>/dev/null | head -10
[ -f "knexfile.js" ] && echo "âœ“ Knex.js"
[ -f "ormconfig.json" ] || [ -f "ormconfig.js" ] && echo "âœ“ TypeORM"

# Look for model/schema files
echo -e "\n=== MODELS/SCHEMAS ==="
find . -name "*model*" -o -name "*schema*" -o -name "*entity*" 2>/dev/null | grep -v node_modules | grep -v __pycache__ | head -20
```

---

## Phase 5: BMAD Gap Analysis

Based on all collected information, assess what BMAD artifacts are needed:

### 5.1 Required BMAD Structure

```bash
echo "=== BMAD STRUCTURE CHECK ==="
[ -d ".bmad-core" ] && echo "âœ“ .bmad-core/ exists" || echo "âœ— .bmad-core/ missing - NEEDS SETUP"
[ -d "docs" ] && echo "âœ“ docs/ exists" || echo "âœ— docs/ missing - NEEDS CREATION"
[ -d "docs/stories" ] && echo "âœ“ docs/stories/ exists" || echo "âœ— docs/stories/ missing"
[ -d "docs/prd" ] && echo "âœ“ docs/prd/ exists" || echo "âœ— docs/prd/ missing"
[ -d "docs/architecture" ] && echo "âœ“ docs/architecture/ exists" || echo "âœ— docs/architecture/ missing"
[ -d ".ai" ] && echo "âœ“ .ai/ exists" || echo "âœ— .ai/ missing - NEEDS CREATION"
[ -f "WARP.md" ] && echo "âœ“ WARP.md exists" || echo "âœ— WARP.md missing"
```

### 5.2 Gap Summary

Present to user:
```
=== BMAD Migration Gap Analysis ===

HAVE (from existing project):
- [x] Source code in [detected structure]
- [x] Tech stack: [summary]
- [x] README with [summary]
- [existing docs list]

NEED TO CREATE:
- [ ] docs/ directory structure
- [ ] docs/prd.md (PRD) - can bootstrap from README
- [ ] docs/architecture.md - can bootstrap from detected stack
- [ ] docs/architecture/tech-stack.md
- [ ] docs/architecture/coding-standards.md
- [ ] docs/architecture/source-tree.md
- [ ] .ai/workflow-state.json
- [ ] .bmad-core/ (copy from template)

OPTIONAL:
- [ ] Project brief (if starting fresh planning)
- [ ] Story sharding (if starting development)
```

**Checkpoint 4:** Present gap analysis. Ask:
```
Based on analysis, here's what needs to be created:

[gap list]

How would you like to proceed?
1. Auto-generate all BMAD artifacts from detected info
2. Step through each artifact manually
3. Just create the structure, I'll fill it in
4. Show me what would be generated first
```

---

## Phase 6: BMAD Structure Creation

### 6.1 Create Directory Structure

```bash
echo "=== CREATING BMAD STRUCTURE ==="
mkdir -p docs/stories
mkdir -p docs/prd
mkdir -p docs/architecture
mkdir -p docs/qa
mkdir -p .ai
echo "âœ“ Directory structure created"
```

### 6.2 Copy .bmad-core (if not present)

```bash
# This assumes template is available - adjust path as needed
if [ ! -d ".bmad-core" ]; then
  echo "Copying .bmad-core from template..."
  # cp -r /path/to/bmad-template/.bmad-core .
  echo "NOTE: Copy .bmad-core manually from template location"
fi
```

### 6.3 Generate tech-stack.md

Based on Phase 2 detection, create `docs/architecture/tech-stack.md`:

```markdown
# Tech Stack

## Core Technologies
[Auto-fill from detection]

## Dependencies
[Auto-fill from package.json/requirements.txt/etc]

## Build & Development
[Auto-fill from detected build tools]

## Testing
[Auto-fill from detected test frameworks]

## Infrastructure
[Auto-fill from detected infra configs]
```

### 6.4 Generate source-tree.md

Based on Phase 4 detection, create `docs/architecture/source-tree.md`:

```markdown
# Source Tree

## Directory Structure
[Auto-generated tree]

## Key Directories
[Purpose of each detected directory]

## Entry Points
[List detected entry points]
```

### 6.5 Bootstrap PRD from README

If README exists, create initial `docs/prd.md` skeleton:

```markdown
# Product Requirements Document

## Project Overview
[Extract from README intro]

## Problem Statement
[Extract or mark as TODO]

## Goals
[Extract from README if present, else TODO]

## Features
[Extract from README features section if present]

## Technical Requirements
[Reference architecture.md]

---
*This PRD was bootstrapped from existing README. Review and expand each section.*
```

### 6.6 Bootstrap Architecture from Detection

Create initial `docs/architecture.md`:

```markdown
# Architecture Document

## System Overview
[Brief description based on detected stack]

## Tech Stack
See: [tech-stack.md](architecture/tech-stack.md)

## Source Structure
See: [source-tree.md](architecture/source-tree.md)

## Key Components
[List main directories/modules detected]

## Data Layer
[Database/ORM info if detected]

## External Integrations
[APIs/services if detected]

---
*This architecture doc was bootstrapped from codebase analysis. Review and expand.*
```

### 6.7 Create workflow-state.json

```bash
cat > .ai/workflow-state.json << EOF
{
  "currentPhase": "BROWNFIELD_ONBOARDED",
  "activeAgent": null,
  "activeStory": null,
  "lastCheckpoint": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
  "uncommittedWork": false,
  "currentBranch": "$(git branch --show-current 2>/dev/null || echo 'main')",
  "completedArtifacts": ["brownfield-migration"],
  "pendingActions": ["review-prd", "review-architecture", "create-stories"],
  "migrationSource": {
    "originalReadme": true,
    "detectedStack": "[STACK_SUMMARY]",
    "migrationDate": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
  }
}
EOF
```

### 6.8 Update .gitignore

```bash
# Add BMAD-specific ignores if not present
if ! grep -q ".ai/\*" .gitignore 2>/dev/null; then
  echo -e "\n# BMAD AI files\n.ai/*\n!.ai/workflow-state.json.template" >> .gitignore
  echo "âœ“ Updated .gitignore"
fi
```

---

## Phase 7: Migration Report

Present final report:

```
ğŸ”„ BMAD Brownfield Migration Complete

ğŸ“Š Project Analysis:
   Repository: [name from git remote or folder]
   Languages: [detected]
   Frameworks: [detected]
   Lines of Code: [if calculated]

ğŸ“ Created Structure:
   âœ“ docs/
   âœ“ docs/stories/
   âœ“ docs/prd/ 
   âœ“ docs/architecture/
   âœ“ .ai/workflow-state.json

ğŸ“„ Generated Artifacts:
   âœ“ docs/prd.md (bootstrapped from README)
   âœ“ docs/architecture.md (bootstrapped from detection)
   âœ“ docs/architecture/tech-stack.md
   âœ“ docs/architecture/source-tree.md

âš ï¸ Requires Manual Review:
   - docs/prd.md - expand requirements
   - docs/architecture.md - add design decisions
   - docs/architecture/coding-standards.md - define standards

ğŸ”® Recommended Next Steps:
   1. Review and refine docs/prd.md with PM agent
   2. Review and refine docs/architecture.md with Architect agent
   3. Run PO to validate and shard documents
   4. Begin story creation with SM agent

Would you like me to:
1. Switch to PM to review/refine the PRD
2. Switch to Architect to review/refine architecture
3. Show detailed migration log
4. Commit migration changes now
```

---

## Rollback (if needed)

If migration needs to be undone:

```bash
# Remove created directories (CAREFUL - only if empty or newly created)
rm -rf docs/stories docs/prd docs/architecture .ai
# Remove generated files
rm -f docs/prd.md docs/architecture.md
# Restore .gitignore if backed up
```

---

## Post-Migration Checklist

- [ ] Review docs/prd.md - ensure it captures actual requirements
- [ ] Review docs/architecture.md - ensure it reflects actual design
- [ ] Create docs/architecture/coding-standards.md based on existing patterns
- [ ] Verify .bmad-core/ is properly installed
- [ ] Run `*help` to confirm orchestrator is functional
- [ ] Create first story to test workflow
